# XML Pipeline: FastAPI + AMQP

Este projeto Ã© um pipeline de alta performance desenhado para processar arquivos ZIP massivos (na escala de GB/TB) contendo documentos XML, extrair dados especÃ­ficos utilizando a biblioteca `lxml` e distribuir essas informaÃ§Ãµes em um broker de mensagens AMQP (RabbitMQ).

## ğŸ—ï¸ Arquitetura e Design Patterns

O projeto segue os princÃ­pios **SOLID** e utiliza padrÃµes de design para garantir escalabilidade:

- **Streaming de Dados:** O processamento do ZIP nÃ£o carrega o arquivo completo em RAM. Ele utiliza geradores (`yield`) e acesso direto ao buffer de disco (`SpooledTemporaryFile`) para manter o consumo de memÃ³ria baixo e constante.
- **Decoupling (Desacoplamento):** A lÃ³gica de parsing, o armazenamento em memÃ³ria e a mensageria sÃ£o classes independentes, facilitando a manutenÃ§Ã£o e testes.
- **Background Tasks:** A publicaÃ§Ã£o no AMQP via endpoint GET Ã© realizada de forma assÃ­ncrona (segundo plano) para garantir tempos de resposta de milissegundos ao usuÃ¡rio.
- **ResiliÃªncia:** Filtros automÃ¡ticos ignoram metadados de sistemas operacionais (como arquivos `._` do macOS) e recuperam erros de encoding em XMLs malformados.

## ğŸ“ Estrutura do Projeto

```text
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # Endpoints FastAPI e Gerenciamento de Estado
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ xml_processor.py # Motor de extraÃ§Ã£o e parsing (lxml)
â”‚   â”‚   â””â”€â”€ amqp.py    # Cliente de integraÃ§Ã£o AMQP (pika)
â”œâ”€â”€ tests/                   # Testes unitÃ¡rios e mocks
â”œâ”€â”€ Dockerfile               # Receita da imagem Python
â”œâ”€â”€ docker-compose.yml       # OrquestraÃ§Ã£o (App + RabbitMQ)
â””â”€â”€ requirements.txt         # DependÃªncias do projeto

```

## ğŸš€ Como Executar

**PrÃ©-requisitos:** Docker e Docker Compose instalados.

1. **Subir o ambiente:**

```bash
docker-compose up --build

```

2. **Acessar a API:**
   A aplicaÃ§Ã£o estarÃ¡ disponÃ­vel em `http://localhost:8000`.

## ğŸ› ï¸ Fluxos Principais

### 1. Upload e ExtraÃ§Ã£o

- **Endpoint:** `POST /upload`
- **Fluxo:** Recebe um ZIP -> Itera via stream -> Valida arquivos -> Faz o parse dos XMLs -> Salva na variÃ¡vel global `DATA_STORAGE`.

### 2. Consulta e PublicaÃ§Ã£o

- **Endpoint:** `GET /extraidos`
- **Fluxo:** Retorna o JSON com os dados da memÃ³ria -> Dispara uma **Background Task** -> Abre conexÃ£o AMQP -> Publica cada item individualmente como mensagem persistente.

## ğŸ“Š Monitoramento e DocumentaÃ§Ã£o

- **API Docs:** A documentaÃ§Ã£o interativa (Swagger) com todos os detalhes dos endpoints pode ser acessada em: `http://localhost:8000/docs`
- **RabbitMQ Management:** Acompanhe as filas, o volume de mensagens e a saÃºde do broker pela interface web: `http://localhost:15672` (UsuÃ¡rio/Senha: `guest`).

## ğŸ§ª Testes

Para rodar a suÃ­te de testes (com mocks de RabbitMQ e simulaÃ§Ã£o de arquivos reais):

```bash
pytest -v

```
